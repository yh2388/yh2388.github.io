<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh_CN">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Spark," />










<meta name="description" content="Spark概述Apache Spark是一个快速且通用的大规模数据处理的引擎。使用Scala编写，Scala是一种函数式的编程语言。它提供了一种交互式的命令行，用于学习和数据探索，分为Python和Scala两种。可以通过Python、Scala或Java来编写Spark应用程序，来进行大规模的数据处理。 Spark ShellSpark Shell 提供了交互式的，通过读取/评估/打印三者循环的">
<meta name="keywords" content="Spark">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark基础">
<meta property="og:url" content="http://yoursite.com/2017/09/18/SparkBasics/index.html">
<meta property="og:site_name" content="T1mon">
<meta property="og:description" content="Spark概述Apache Spark是一个快速且通用的大规模数据处理的引擎。使用Scala编写，Scala是一种函数式的编程语言。它提供了一种交互式的命令行，用于学习和数据探索，分为Python和Scala两种。可以通过Python、Scala或Java来编写Spark应用程序，来进行大规模的数据处理。 Spark ShellSpark Shell 提供了交互式的，通过读取/评估/打印三者循环的">
<meta property="og:locale" content="zh_CN">
<meta property="og:updated_time" content="2017-09-19T03:20:01.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Spark基础">
<meta name="twitter:description" content="Spark概述Apache Spark是一个快速且通用的大规模数据处理的引擎。使用Scala编写，Scala是一种函数式的编程语言。它提供了一种交互式的命令行，用于学习和数据探索，分为Python和Scala两种。可以通过Python、Scala或Java来编写Spark应用程序，来进行大规模的数据处理。 Spark ShellSpark Shell 提供了交互式的，通过读取/评估/打印三者循环的">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2017/09/18/SparkBasics/"/>





  <title>Spark基础 | T1mon</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh_CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">T1mon</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/09/18/SparkBasics/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="俞淙">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="T1mon">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Spark基础</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-09-18T20:40:50+08:00">
                2017-09-18
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h4 id="Spark概述"><a href="#Spark概述" class="headerlink" title="Spark概述"></a>Spark概述</h4><p>Apache Spark是一个快速且通用的大规模数据处理的引擎。使用Scala编写，Scala是一种函数式的编程语言。<br>它提供了一种交互式的命令行，用于学习和数据探索，分为Python和Scala两种。可以通过Python、Scala或Java<br>来编写Spark应用程序，来进行大规模的数据处理。</p>
<h5 id="Spark-Shell"><a href="#Spark-Shell" class="headerlink" title="Spark Shell"></a>Spark Shell</h5><p>Spark Shell 提供了交互式的，通过读取/评估/打印三者循环的处理模式，来进行数据的探索，就像使用命令行<br>一样方便</p>
<h5 id="Spark-Context"><a href="#Spark-Context" class="headerlink" title="Spark Context"></a>Spark Context</h5><p>每一个Spark应用程序都必须要有一个SparkContext，它是SparkAPI的主要入口点。</p>
<p>在启动Spark Shell后，我们会在终端中看到一段这样的描述：<code>Spark context available as sc</code>。<br>这是Spark Shell提供的一个预配置的SparkContext，称为<code>sc</code>。</p>
<a id="more"></a>
<h4 id="RDD-Resilient-Distributed-Dataset"><a href="#RDD-Resilient-Distributed-Dataset" class="headerlink" title="RDD (Resilient Distributed Dataset)"></a>RDD (Resilient Distributed Dataset)</h4><p>弹性分布式数据集：</p>
<pre><code>1. 弹性的：如果存在内存中的数据丢失了，可以被重新创建
2. 分布式：跨集群处理
3. 数据集：初始数据可来自于一个文件，也可以通过编程方式创建
</code></pre><p>RDD是Spark中最基本的数据单元</p>
<h5 id="Creating-an-RDD"><a href="#Creating-an-RDD" class="headerlink" title="Creating an RDD"></a>Creating an RDD</h5><p>我们可以通过三种方式来创建一个RDD：</p>
<pre><code>1. 从一个文件或一个文件集
2. 从内存中的数据
3. 从另一个RDD
</code></pre><p>基于文件创建一个RDD：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">val mydata=sc.textFile(<span class="string">"purplecow.txt"</span>)</span><br><span class="line">mydata.count()</span><br></pre></td></tr></table></figure></p>
<h5 id="RDD-Operations"><a href="#RDD-Operations" class="headerlink" title="RDD Operations"></a>RDD Operations</h5><p>RDD的操作有两种，一种是<code>Action</code>，它会返回值，另一个是<code>Transformations</code>，它会基于当前的RDD来定义一个<br>新的RDD。</p>
<h6 id="RDD-Operations-Actions"><a href="#RDD-Operations-Actions" class="headerlink" title="RDD Operations:Actions"></a>RDD Operations:Actions</h6><p>常见的Action有<code>count()</code>、<code>take(n)</code>、<code>collect()</code>和<code>saveAsTextFile()</code>,使用它们来实现对RDD的一些基本操作，<br>例如统计RDD中元素的个数，获取一定数量的元素，获取全部以及将RDD保存为textFile格式的文件。</p>
<h6 id="RDD-Operations-Transformations"><a href="#RDD-Operations-Transformations" class="headerlink" title="RDD Operations:Transformations"></a>RDD Operations:Transformations</h6><p>Transformations会从现有的一个RDD中创建出一个新的RDD，我们要知道的是数据在RDD中是不会被改变的，<br>可根据需要修改数据并按顺序来转换成新的RDD。</p>
<p>常见的Transformations有：</p>
<p><code>map(function)</code>：通过在一个RDD的每条记录上执行一个函数来创建一个新的RDD。</p>
<p><code>fileter(function)</code>：根据一个布尔函数，筛选或过滤原RDD中的每一条记录，从而创建一个<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mydate.map(line=&gt;line.toUpperCase).filter(line=&gt;line.startsWith(<span class="string">"I"</span>))</span><br></pre></td></tr></table></figure></p>
<h4 id="Lazy-Execution"><a href="#Lazy-Execution" class="headerlink" title="Lazy Execution"></a>Lazy Execution</h4><p>懒执行的概念与Hibernate框架的懒加载相似。在Hibernate中，session的load()方法具有懒加载的特性，其作用是<br>降低程序与数据库之间的交互频率，通过load()查询某一条数据的时候并不会直接将这条数据以指定对象的<br>形式来返回，而是在你真正需要使用该对象里面的一些属性的时候才会去数据库访问并得到数据，因此这样的方式可<br>以提高程序的运行效率。</p>
<p>所有的Transformations操作都使用了lazy，它们不会计算结果，只是记录dataset的转换操作。因此，在执行Action<br>操作前数据在RDD中是不会被处理的。</p>
<p>Transformations操作也可以连在一起，作为一个链式的操作进行执行。</p>
<p>参考：<a href="http://www.jianshu.com/p/b60dfb856312" target="_blank" rel="noopener">http://www.jianshu.com/p/b60dfb856312</a></p>
<h6 id="RDD-Lineage-and-toDebugString"><a href="#RDD-Lineage-and-toDebugString" class="headerlink" title="RDD Lineage and toDebugString"></a>RDD Lineage and toDebugString</h6><p>Spark会维护每个RDD的<code>lineage</code>关系，即它所依赖的以前的RDD与其的关系。<br>执行下面的代码：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> mydata_filt =sc.textFile(<span class="string">"purplecow.txt"</span>).map(line =&gt; line.toUpperCase()).filter(line =&gt; line.startsWith(<span class="string">"I"</span>))</span><br><span class="line">mydata_filt.toDebugString</span><br></pre></td></tr></table></figure></p>
<p>我们可以看到输出结果为：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(<span class="number">1</span>) <span class="type">MapPartitionsRDD</span>[<span class="number">5</span>] at filter at &lt;console&gt;:<span class="number">27</span> []</span><br><span class="line"> |  <span class="type">MapPartitionsRDD</span>[<span class="number">4</span>] at map at &lt;console&gt;:<span class="number">27</span> []</span><br><span class="line"> |  purplecow.txt <span class="type">MapPartitionsRDD</span>[<span class="number">3</span>] at textFile at &lt;console&gt;:<span class="number">27</span> []</span><br><span class="line"> |  purplecow.txt <span class="type">HadoopRDD</span>[<span class="number">2</span>] at textFile at &lt;console&gt;:<span class="number">27</span> []</span><br></pre></td></tr></table></figure></p>
<p>通过这些输出的结果，我们可以清晰的看出当前RDD与之前的RDD的各种依赖关系。</p>
<h6 id="Pipelining"><a href="#Pipelining" class="headerlink" title="Pipelining"></a>Pipelining</h6><p>在可能的情况下，Spark会顺序执行Transformations操作，因此不会存储数据。</p>
<p>在后续的练习中出现了数据被存储下来的情况，RDD 的 Transformation 函数中,又分为窄依赖(narrow dependency)和宽依赖(wide dependency)的操作。窄依赖跟宽依赖的区别是是否发生 shuffle(洗牌) 操作。宽依赖会发生 shuffle 操作。窄依赖是子 RDD的各个分片(partition)不依赖于其他分片,能够独立计算得到结果,宽依赖指子 RDD 的各个分片会依赖于父RDD 的多个分片,所以会造成父 RDD 的各个分片在集群中重新分片。窄依赖中，RDD中的各个数据元素之间不存在依赖，可以在集群的各个内存中独立计算，也就是并行。而进行宽依赖后的操作，例如groupBy,为了计算相同 key 下的元素个数,需要把相同 key 的元素聚集到同一个 partition 下,所以造成了数据在内存中的重新分布,即 shuffle 操作.shuffle 操作是 spark 中最耗时的操作,应尽量避免不必要的 shuffle。</p>
<p>宽依赖主要有两个过程: shuffle write 和 shuffle fetch. 类似 Hadoop 的 Map 和 Reduce 阶段.shuffle write 将 ShuffleMapTask 任务产生的中间结果缓存到内存中, shuffle fetch 获得 ShuffleMapTask 缓存的中间结果进行 ShuffleReduceTask 计算,这个过程容易造成OutOfMemory. </p>
<p>shuffle 过程内存分配使用 ShuffleMemoryManager 类管理,会针对每个 Task 分配内存,Task 任务完成后通过 Executor 释放空间.早期的内存分配机制使用公平分配,即不同 Task 分配的内存是一样的,但是这样容易造成内存需求过多的 Task 的 OutOfMemory, 从而造成多余的 磁盘 IO 过程,影响整体的效率这里可以把 Task 理解成不同 key 的数据对应一个 Task.(例:某一个 key 下的数据明显偏多,但因为大家内存都一样,这一个 key 的数据就容易 OutOfMemory).1.5版以后 Task 共用一个内存池,内存池的大小默认为 JVM 最大运行时内存容量的16%,分配机制如下::假如有 N 个 Task,ShuffleMemoryManager 保证每个 Task 溢出之前至少可以申请到1/2N 内存,且至多申请到1/N,N 为当前活动的 shuffle Task 数,因为N 是一直变化的,所以 manager 会一直追踪 Task 数的变化,重新计算队列中的1/N 和1/2N.但是这样仍然容易造成内存需要多的 Task 任务溢出,所以最近有很多相关的研究是针对 shuffle 过程内存优化的. </p>
<p>上面描述了shuffle过程内存分配的问题，但是，当shuffle的结果量非常大，而内存不够时，要不就失败，要不就用老办法把内存中的数据移到磁盘上放着。Spark意识到在处理数据规模远远大于内存空间时所带来的不足，引入了一个具有外部排序的方案。Shuffle过来的数据先放在内存中，当内存中存储的<key, value="">对超过1000并且内存使用超过70%时，判断节点上可用内存如果还足够，则把内存缓冲区大小翻倍，如果可用内存不再够了，则把内存中的<key, value="">对排序然后写到磁盘文件中。最后把内存缓冲区中的数据排序之后和那些磁盘文件组成一个最小堆，每次从最小堆中读取最小的数据，这个和MapReduce中的merge过程类似。</key,></key,></p>
<p>参考：</p>
<pre><code>1. http://blog.csdn.net/pzw_0612/article/details/53150004
2. http://blog.csdn.net/databatman/article/details/53023818
3. http://www.cnblogs.com/jxhd1/p/6528540.html
</code></pre><h4 id="Functional-Programming-in-Spark"><a href="#Functional-Programming-in-Spark" class="headerlink" title="Functional Programming in Spark"></a>Functional Programming in Spark</h4><p>Spark很大程度上依赖于函数式编程的概念：函数是程序的最基本单位，仅有输入和输出，没有状态和其他的影响。</p>
<p>关键概念：将函数作为另一个函数的输入；匿名函数。</p>
<h6 id="Passing-Functions-as-Parameters"><a href="#Passing-Functions-as-Parameters" class="headerlink" title="Passing Functions as Parameters"></a>Passing Functions as Parameters</h6><p>许多RDD的操作使用函数作为参数，下面有一段伪代码，表示将函数fn应用到RDD中的每个记录：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">RDD</span> &#123;</span><br><span class="line">    map(fn(x)) &#123;</span><br><span class="line">        foreach record in rdd</span><br><span class="line">        emit fn(record)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>下面有一个通过定义一个函数，将该函数作为参数传入map中的例子：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">toUpper</span></span>(s: <span class="type">String</span>): <span class="type">String</span> =&#123; s.toUpperCase &#125;</span><br><span class="line"><span class="keyword">val</span> mydata = sc.textFile(<span class="string">"purplecow.txt"</span>)</span><br><span class="line">mydata.map(toUpper).take(<span class="number">2</span>)</span><br></pre></td></tr></table></figure></p>
<h6 id="Anonymous-Functions"><a href="#Anonymous-Functions" class="headerlink" title="Anonymous Functions"></a>Anonymous Functions</h6><p>匿名函数是没有标识符的内联函数，那些代码量少或只执行一次的函数，我们就可以将其写为匿名函数。<br>很多语言支持匿名函数，例如Python、Scala、Java8。下面是一个Scala匿名函数操作的例子：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mydata.map(line =&gt; line.toUpperCase()).take(<span class="number">2</span>)</span><br><span class="line"><span class="comment">//Scala允许在匿名参数使用下划线(_)代替</span></span><br><span class="line"><span class="comment">//mydata.map(_.toUpperCase()).take(2)</span></span><br></pre></td></tr></table></figure></p>
<p>在java中，由于java8提供了新的语法特性，因此在编写匿名函数时，相较于之前的版本会更加简洁。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//java7的写法</span></span><br><span class="line">JavaRDD&lt;String&gt; mydata = sc.textFile(<span class="string">"file"</span>);</span><br><span class="line">JavaRDD&lt;String&gt; mydata_uc = mydata.map(<span class="keyword">new</span> Function&lt;String,String&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">call</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> (s.toUpperCase());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line"><span class="comment">//java8的写法</span></span><br><span class="line">JavaRDD&lt;String&gt; lines = sc.textFile(<span class="string">"file"</span>);</span><br><span class="line">JavaRDD&lt;String&gt; lines_uc = lines.map(line -&gt; line.toUpperCase());</span><br></pre></td></tr></table></figure>
<h4 id="Essential-Points"><a href="#Essential-Points" class="headerlink" title="Essential Points"></a>Essential Points</h4><p>对以上内容做一个总结：</p>
<ol>
<li>Spark可以通过Spark Shell交互式地使用，支持Python或Scala语言。</li>
<li>RDDs(弹性分布式数据集)是Spark中的一个关键概念。</li>
<li>RDD操作<ul>
<li>Transformations操作基于现有的RDD来创建一个新的RDD。</li>
<li>Action操作会返回RDD的一个值。</li>
</ul>
</li>
<li>懒执行。</li>
<li>Spark使用了函数使编程。</li>
</ol>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Spark/" rel="tag"># Spark</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/08/21/servletAndspring/" rel="next" title="servlet中spring注解自动注入失败的问题">
                <i class="fa fa-chevron-left"></i> servlet中spring注解自动注入失败的问题
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="lv-container" data-id="city" data-uid="MTAyMC8zNDAwMC8xMDUzNQ=="></div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">俞淙</p>
              <p class="site-description motion-element" itemprop="description">一步一个脚印</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">21</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">10</span>
                  <span class="site-state-item-name">tags</span>
                
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#Spark概述"><span class="nav-number">1.</span> <span class="nav-text">Spark概述</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Spark-Shell"><span class="nav-number">1.1.</span> <span class="nav-text">Spark Shell</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Spark-Context"><span class="nav-number">1.2.</span> <span class="nav-text">Spark Context</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#RDD-Resilient-Distributed-Dataset"><span class="nav-number">2.</span> <span class="nav-text">RDD (Resilient Distributed Dataset)</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Creating-an-RDD"><span class="nav-number">2.1.</span> <span class="nav-text">Creating an RDD</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#RDD-Operations"><span class="nav-number">2.2.</span> <span class="nav-text">RDD Operations</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#RDD-Operations-Actions"><span class="nav-number">2.2.1.</span> <span class="nav-text">RDD Operations:Actions</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#RDD-Operations-Transformations"><span class="nav-number">2.2.2.</span> <span class="nav-text">RDD Operations:Transformations</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Lazy-Execution"><span class="nav-number">3.</span> <span class="nav-text">Lazy Execution</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#RDD-Lineage-and-toDebugString"><span class="nav-number">3.0.1.</span> <span class="nav-text">RDD Lineage and toDebugString</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Pipelining"><span class="nav-number">3.0.2.</span> <span class="nav-text">Pipelining</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Functional-Programming-in-Spark"><span class="nav-number">4.</span> <span class="nav-text">Functional Programming in Spark</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#Passing-Functions-as-Parameters"><span class="nav-number">4.0.1.</span> <span class="nav-text">Passing Functions as Parameters</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Anonymous-Functions"><span class="nav-number">4.0.2.</span> <span class="nav-text">Anonymous Functions</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Essential-Points"><span class="nav-number">5.</span> <span class="nav-text">Essential Points</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">俞淙</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  
    <script type="text/javascript">
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  












  





  

  

  

  
  

  

  

  

</body>
</html>
